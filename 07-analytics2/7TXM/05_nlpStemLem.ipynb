{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dc7a0c4a",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "- Getting root form of the word\n",
    "- Process - Remoe  Prefix of suffix of the word, so word may not result in the acutal words\n",
    "- the words “programming,” “programmer,” and “programs” can all be reduced down to the common word stem “program.”\n",
    " - creative, creating created, creating, creates -> create"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e75829",
   "metadata": {},
   "source": [
    "## Stem methods\n",
    "- PorterStemmer\n",
    "- RegexStemme\n",
    "- SnowballStemm\n",
    "- LancasterStem\n",
    "- https://www.geeksforgeeks.org/introduction-to-stemming/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6c912df",
   "metadata": {},
   "source": [
    "Stemming\t\n",
    "- Stemming is a process that stems or removes last few characters from a word, often leading to incorrect meanings and spelling.\n",
    "- For instance, stemming the word ‘Caring‘ would return ‘Car‘.\n",
    "- Stemming is used in case of large dataset where performance is an issue.\n",
    "\n",
    "Lemmatization\n",
    "- Lemmatization considers the context and converts the word to its meaningful base form, which is called Lemma.\n",
    "- For instance, lemmatizing the word ‘Caring‘ would return ‘Care‘.\n",
    "- Lemmatization is computationally expensive since it involves look-up tables and what not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0a07a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e41763",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a03017e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The quick brown fox jumps over the lazy little dog. Alice went up the hill and got a pale of water'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p1 = 'The quick brown fox jumps over the lazy little dog. Alice went up the hill and got a pale of water'\n",
    "p1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43ca8bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12345'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = '1' + '2' + '3' + \\\n",
    "    '4' + '5'\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "babc5c4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'creative, creating created, creating, creates. Consult Consultant Consulting Consultantive Consultants Consulting.  Connections connection connected connecting ; waited waiting waits studying studies study eating eats bodly pharmacies change changing changes changed changer caringhistory historical finally final likes liked likely liking children understood whom best books'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = 'creative, creating created, creating, creates. '\n",
    "s2 = 'Consult Consultant Consulting Consultantive Consultants Consulting.  '\n",
    "s3 = 'Connections connection connected connecting ; '\n",
    "s4 = 'waited waiting waits '\n",
    "s5 = 'studying studies study '  # study\n",
    "s6 = 'eating eats bodly pharmacies '  # eat, eat, badli pharmaci\n",
    "s7 = 'change changing changes changed changer '  # change (lem - change)\n",
    "s8 = 'caring'  # L -care, S-car\n",
    "s9 = 'history historical finally final '  # histori fina\n",
    "s10 = 'likes liked likely liking '\n",
    "s11 = 'children understood whom best books'  # child, understand who good\n",
    "p2 = s1 + s2 +  s3 + s4 + s5 +\\\n",
    "    s6 + s7 + s8 + s9 + s10 + s11\n",
    "p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "02888461",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer, LancasterStemmer, RegexpStemmer, SnowballStemmer\n",
    "\n",
    "from nltk import sent_tokenize\n",
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "942ded58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('arabic', 'danish', 'dutch', 'english', 'finnish', 'french', 'german', 'hungarian', 'italian', 'norwegian', 'porter', 'portuguese', 'romanian', 'russian', 'spanish', 'swedish') \t\n"
     ]
    }
   ],
   "source": [
    "print(SnowballStemmer.languages, '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "6055d4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_stem = PorterStemmer()\n",
    "l_stem = LancasterStemmer()\n",
    "r_stem = RegexpStemmer('ing')  #what u want to remove her ing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "486e244e",
   "metadata": {},
   "outputs": [],
   "source": [
    "en_stem = SnowballStemmer('english')\n",
    "fr_stem = SnowballStemmer('french')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "61d7c5fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['creative, creating created, creating, creates.',\n",
       " 'Consult Consultant Consulting Consultantive Consultants Consulting.',\n",
       " 'Connections connection connected connecting ; waited waiting waits studying studies study eating eats bodly pharmacies change changing changes changed changer caringhistory historical finally final likes liked likely liking children understood whom best books']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence = sent_tokenize(p2)\n",
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "0400bbdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creative', ',', 'creating', 'created', ',', 'creating', ',', 'creates', '.', 'Consult', 'Consultant', 'Consulting', 'Consultantive', 'Consultants', 'Consulting', '.', 'Connections', 'connection', 'connected', 'connecting', ';', 'waited', 'waiting', 'waits', 'studying', 'studies', 'study', 'eating', 'eats', 'bodly', 'pharmacies', 'change', 'changing', 'changes', 'changed', 'changer', 'caringhistory', 'historical', 'finally', 'final', 'likes', 'liked', 'likely', 'liking', 'children', 'understood', 'whom', 'best', 'books'] \t\n"
     ]
    }
   ],
   "source": [
    "words = word_tokenize(p2)\n",
    "print(words, '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "c456f6ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word -  writing eating eats\n",
      "Porter Stemmer -  write \t eat eat\n",
      "Lancaster Stemmer -  writ \t eat eat\n",
      "Regexp Stemmer -  writ \t eat eats\n"
     ]
    }
   ],
   "source": [
    "# 1 word\n",
    "print('Word - ', 'writing', 'eating', 'eats')\n",
    "\n",
    "print('Porter Stemmer - ', p_stem.stem('writing') ,'\\t',  p_stem.stem('eating'), p_stem.stem('eats'))\n",
    "print('Lancaster Stemmer - ', l_stem.stem('writing') ,'\\t',  l_stem.stem('eating'),l_stem.stem('eats'))\n",
    "print('Regexp Stemmer - ', r_stem.stem('writing') ,'\\t',  r_stem.stem('eating'), r_stem.stem('eats'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "345f14a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bonjour'"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_stem.stem ('Bonjoura')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "39e0f8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creative', ',', 'creating', 'created', ',', 'creating', ',', 'creates', '.', 'Consult', 'Consultant', 'Consulting', 'Consultantive', 'Consultants', 'Consulting', '.', 'Connections', 'connection', 'connected', 'connecting', ';', 'waited', 'waiting', 'waits', 'studying', 'studies', 'study', 'eating', 'eats', 'bodly', 'pharmacies', 'change', 'changing', 'changes', 'changed', 'changer', 'caringhistory', 'historical', 'finally', 'final', 'likes', 'liked', 'likely', 'liking', 'children', 'understood', 'whom', 'best', 'books'] \t\n"
     ]
    }
   ],
   "source": [
    "print([i for i in words], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "ff705554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creativ', ',', 'creat', 'creat', ',', 'creat', ',', 'creat', '.', 'consult', 'consult', 'consult', 'consultant', 'consult', 'consult', '.', 'connect', 'connect', 'connect', 'connect', ';', 'wait', 'wait', 'wait', 'studi', 'studi', 'studi', 'eat', 'eat', 'bodli', 'pharmaci', 'chang', 'chang', 'chang', 'chang', 'changer', 'caringhistori', 'histor', 'final', 'final', 'like', 'like', 'like', 'like', 'children', 'understood', 'whom', 'best', 'book'] \t\n"
     ]
    }
   ],
   "source": [
    "print([p_stem.stem(word) for word in words], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "6c66b519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cre', ',', 'cre', 'cre', ',', 'cre', ',', 'cre', '.', 'consult', 'consult', 'consult', 'consult', 'consult', 'consult', '.', 'connect', 'connect', 'connect', 'connect', ';', 'wait', 'wait', 'wait', 'study', 'study', 'study', 'eat', 'eat', 'bod', 'pharm', 'chang', 'chang', 'chang', 'chang', 'chang', 'caringh', 'hist', 'fin', 'fin', 'lik', 'lik', 'lik', 'lik', 'childr', 'understood', 'whom', 'best', 'book'] \t\n"
     ]
    }
   ],
   "source": [
    "print([l_stem.stem(word) for word in words], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7ad6e4dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creative', ',', 'creat', 'created', ',', 'creat', ',', 'creates', '.', 'Consult', 'Consultant', 'Consult', 'Consultantive', 'Consultants', 'Consult', '.', 'Connections', 'connection', 'connected', 'connect', ';', 'waited', 'wait', 'waits', 'study', 'studies', 'study', 'eat', 'eats', 'bodly', 'pharmacies', 'change', 'chang', 'changes', 'changed', 'changer', 'carhistory', 'historical', 'finally', 'final', 'likes', 'liked', 'likely', 'lik', 'children', 'understood', 'whom', 'best', 'books'] \t\n"
     ]
    }
   ],
   "source": [
    "print([r_stem.stem(word) for word in words], '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "29a4623a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creativ', ',', 'creat', 'creat', ',', 'creat', ',', 'creat', '.', 'consult', 'consult', 'consult', 'consultant', 'consult', 'consult', '.', 'connect', 'connect', 'connect', 'connect', ';', 'wait', 'wait', 'wait', 'studi', 'studi', 'studi', 'eat', 'eat', 'bod', 'pharmaci', 'chang', 'chang', 'chang', 'chang', 'changer', 'caringhistori', 'histor', 'final', 'final', 'like', 'like', 'like', 'like', 'children', 'understood', 'whom', 'best', 'book'] \t\n"
     ]
    }
   ],
   "source": [
    "print([en_stem.stem(word) for word in words], '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7baa2865",
   "metadata": {},
   "source": [
    "### What are the errors that could occur in stemming?\n",
    "- There are mainly two errors that could occur in stemming:\n",
    "    - Over-stemming - When two words are stemmed from the same root that are of different stems. Over-stemming can also be regarded as false positives \n",
    "    - Under-stemming - When two words are stemmed from the same root that are not of different stems. Under-stemming can be interpreted as false negatives. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efe624de",
   "metadata": {},
   "source": [
    "## Lemmatization\n",
    "- Lemmatization technique is like stemming. The output we will get after lemmatization is called ‘lemma’, which is a root word rather than root stem, the output of stemming. After lemmatization, we will be getting a valid word that means the same thing.\n",
    "\n",
    "- NLTK provides WordNetLemmatizer class which is a thin wrapper around the wordnet corpus. This class uses morphy() function to the WordNet CorpusReader class to find a lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "c1c37f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "wn_lem = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "52407ca5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating \t Books -  book book\n"
     ]
    }
   ],
   "source": [
    "print(wn_lem.lemmatize('eating'), '\\t Books - ' , wn_lem.lemmatize('books'), wn_lem.lemmatize(words[-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cf733ef4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['me', 'my', 'myself', 'we']\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english')[1:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "267f72b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creative', ',', 'creating', 'created', ',', 'creating', ',', 'creates', '.', 'Consult', 'Consultant', 'Consulting', 'Consultantive', 'Consultants', 'Consulting', '.', 'Connections', 'connection', 'connected', 'connecting', ';', 'waited', 'waiting', 'wait', 'studying', 'study', 'study', 'eating', 'eats', 'bodly', 'pharmacy', 'change', 'changing', 'change', 'changed', 'changer', 'caringhistory', 'historical', 'finally', 'final', 'like', 'liked', 'likely', 'liking', 'child', 'understood', 'best', 'book']\n"
     ]
    }
   ],
   "source": [
    "wn_lem = WordNetLemmatizer()\n",
    "#wordsLem = []\n",
    "#for i in words:\n",
    "    #print(i)\n",
    "wordsLem = [wn_lem.lemmatize(word) for word in words if word not in set(stopwords.words('english'))]\n",
    "    \n",
    "#sentLem = []\n",
    "# Lemmatization\n",
    "#for i in range(len(p2)):\n",
    "#    words = nltk.word_tokenize(p2)\n",
    "#    words = [wn_lem.lemmatize(word) \n",
    "    #sentLem[i] = ' '.join(words)\n",
    "print(wordsLem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "17f7ee18",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['creative', ',', 'creating', 'created', ',', 'creating', ',', 'creates', '.', 'Consult', 'Consultant', 'Consulting', 'Consultantive', 'Consultants', 'Consulting', '.', 'Connections', 'connection', 'connected', 'connecting', ';', 'waited', 'waiting', 'waits', 'studying', 'studies', 'study', 'eating', 'eats', 'bodly', 'pharmacies', 'change', 'changing', 'changes', 'changed', 'changer', 'caringhistory', 'historical', 'finally', 'final', 'likes', 'liked', 'likely', 'liking', 'children', 'understood', 'whom', 'best', 'books']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "ad390bec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word- bats :Stem- bat Lemme- bat\n",
      "Word- are :Stem- are Lemme- are\n",
      "Word- feet :Stem- feet Lemme- foot\n"
     ]
    }
   ],
   "source": [
    "#more egs\n",
    "words2 = ['bats', 'are', 'feet', 'New', 'York', 'is', 'the', 'densely', 'populated', \\\n",
    "         'United', 'States', 'India', 'city', 'information', 'informative', 'computers']\n",
    "i=0\n",
    "print('Word-', words2[i], ':Stem-', p_stem.stem(words2[i]), 'Lemme-', wn_lem.lemmatize(words2[i]))\n",
    "i=1\n",
    "print('Word-', words2[i], ':Stem-', p_stem.stem(words2[i]), 'Lemme-', wn_lem.lemmatize(words2[i]))\n",
    "i=2\n",
    "print('Word-', words2[i], ':Stem-', p_stem.stem(words2[i]), 'Lemme-', wn_lem.lemmatize(words2[i]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "ae5afdf0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bat are foot New York is the densely populated United States India city information informative computer'"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([wn_lem.lemmatize(w) for w in words2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "dc637306",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bat are feet new york is the dens popul unit state india citi inform inform comput'"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join([p_stem.stem(w) for w in words2])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1155d1c7",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "- The output of both programs tells the major difference between stemming and lemmatization. PorterStemmer class chops off the ‘es’ from the word. On the other hand, WordNetLemmatizer class finds a valid word. In simple words, stemming technique only looks at the form of the word whereas lemmatization technique looks at the meaning of the word. It means after applying lemmatization, we will always get a valid word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8d36c17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "word_stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "218bcc41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stemmer -  believ  \t :: Lemma -   believes \n"
     ]
    }
   ],
   "source": [
    "print('Stemmer - ', word_stemmer.stem('believes'), ' \\t :: Lemma - ', lemmatizer.lemmatize(' believes '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afdb80a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
