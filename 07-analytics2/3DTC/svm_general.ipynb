{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcf79cc7",
   "metadata": {},
   "source": [
    "## SVM - Support Vector Machine\n",
    "Decision Tree Technqiue\n",
    "https://scikit-learn.org/stable/modules/svm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b42b97b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pydataset import data\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "62861a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVM\n",
    "from sklearn import svm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57d4c45e",
   "metadata": {},
   "source": [
    "### Classification\n",
    "SVC, NuSVC and LinearSVC are classes capable of performing binary and multi-class classification on a dataset\n",
    "SVC and NuSVC are similar methods, but accept slightly different sets of parameters and have different mathematical formulations (see section Mathematical formulation). On the other hand, LinearSVC is another (faster) implementation of Support Vector Classification for the case of a linear kernel. Note that LinearSVC does not accept parameter kernel, as this is assumed to be linear. It also lacks some of the attributes of SVC and NuSVC, like support_\n",
    "As other classifiers, SVC, NuSVC and LinearSVC take as input two arrays: an array X of shape (n_samples, n_features) holding the training samples, and an array y of class labels (strings or integers), of shape (n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b20a3da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0]\n",
      " [1 1]\n",
      " [0 1]]\n"
     ]
    }
   ],
   "source": [
    "X = [[0,0],[1,1]]\n",
    "y = [0,1]\n",
    "print(np.vstack((X,y)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03976967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0.]\n",
      " [1. 1.]]\n",
      "[0 1]\n",
      "[1 1]\n"
     ]
    }
   ],
   "source": [
    "clf = svm.SVC()\n",
    "clf.fit(X,y)\n",
    "print(clf.support_vectors_) # get support vectors\n",
    "print(clf.support_) # get indices of support vectors\n",
    "print(clf.n_support_) # get number of support vectors for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82b12e4",
   "metadata": {},
   "source": [
    "### Regression\n",
    "The method of Support Vector Classification can be extended to solve regression problems. This method is called Support Vector Regression.\n",
    "The model produced by support vector classification (as described above) depends only on a subset of the training data, because the cost function for building the model does not care about training points that lie beyond the margin. Analogously, the model produced by Support Vector Regression depends only on a subset of the training data, because the cost function ignores samples whose prediction is close to their target.\n",
    "There are three different implementations of Support Vector Regression: SVR, NuSVR and LinearSVR. LinearSVR provides a faster implementation than SVR but only considers the linear kernel, while NuSVR implements a slightly different formulation than SVR and LinearSVR. See Implementation details for further details.\n",
    "As with classification classes, the fit method will take as argument vectors X, y, only that in this case y is expected to have floating point values instead of integer values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3f2f9247",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.5])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "X = [[0, 0], [2, 2]]\n",
    "y = [0.5, 2.5]\n",
    "regr = svm.SVR()\n",
    "regr.fit(X, y)\n",
    "regr.predict([[1, 1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc67e592",
   "metadata": {},
   "source": [
    "### Scaling\n",
    "Support Vector Machine algorithms are not scale invariant, so it is highly recommended to scale your data. For example, scale each attribute on the input vector X to [0,1] or [-1,+1], or standardize it to have mean 0 and variance 1\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVC\n",
    "clf = make_pipeline(StandardScaler(), SVC())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe319120",
   "metadata": {},
   "source": [
    "### unbalanced Data\n",
    "In problems where it is desired to give more importance to certain classes or certain individual samples, the parameters class_weight and sample_weight can be used."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a829c3",
   "metadata": {},
   "source": [
    "### Multi-class classification\n",
    "SVC and NuSVC implement the “one-versus-one” approach for multi-class classification. In total, n_classes * (n_classes - 1) / 2 classifiers are constructed and each one trains data from two classes. To provide a consistent interface with other classifiers, the decision_function_shape option allows to monotonically transform the results of the “one-versus-one” classifiers to a “one-vs-rest” decision function of shape (n_samples, n_classes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "883bdc17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [[0], [1], [2], [3]]\n",
    "Y = [0, 1, 2, 3]\n",
    "clf = svm.SVC(decision_function_shape='ovo')\n",
    "clf.fit(X, Y)\n",
    "#SVC(decision_function_shape='ovo')\n",
    "dec = clf.decision_function([[1]])\n",
    "dec.shape[1] # 4 classes: 4*3/2 = 6\n",
    "#6\n",
    "clf.decision_function_shape = \"ovr\"\n",
    "dec = clf.decision_function([[1]])\n",
    "dec.shape[1] # 4 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e421979f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
