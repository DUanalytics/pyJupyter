{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1ee2893d-432b-4ce3-86a9-450315bff687",
   "metadata": {},
   "source": [
    "# Scraping from Git - Not Working\n",
    "https://github.com/khuyentran1401/Data-science/blob/master/scraping/scrape_top_github.ipynb\n",
    "https://github.com/nelsonic/github-scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "880e4989-4dbd-4cee-b441-ef6d7855c8d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install top_github_scraper\n",
    "#!pip install datapane\n",
    "#!pip install geopandas\n",
    "#!pip install geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "76e863a3-2366-43f9-b838-8749bc124bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from top_github_scraper import (get_top_repo_urls, get_top_repos, get_top_contributors, \n",
    "get_top_user_urls, get_top_users)\n",
    "import datapane as dp \n",
    "import pandas as pd \n",
    "from tqdm import tqdm \n",
    "from folium import plugins\n",
    "import geopandas\n",
    "from geopy.geocoders import Nominatim\n",
    "import folium\n",
    "from folium.plugins import Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "71da00e4-376f-44f9-9ff7-8dffc0bda90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "keyword = \"machine learning\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2629b2cf-db2e-433d-bcc3-7f20a6d3039c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping top GitHub repositories...:   0%|                                                      | 0/90 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'stargazers_count'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "<rich.jupyter.JupyterRenderable at 0x1fb24e98820>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:You might ran out of rate limit. Are you an authenticated user? If you ran out of rate limit while requesting as an authenticated user, \n",
      "        either decrease the number of pages to scrape or to wait until more requests are available.\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './top_repo_info_machine learning_best_match_1_10.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [19], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m contributors \u001b[38;5;241m=\u001b[39m \u001b[43mget_top_contributors\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyword\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop_page\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\top_github_scraper\\scrape_repo.py:275\u001b[0m, in \u001b[0;36mget_top_contributors\u001b[1;34m(keyword, sort_by, max_n_top_contributors, start_page, stop_page, get_user_info_only, save_directory)\u001b[0m\n\u001b[0;32m    266\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m Path(full_repo_save_path)\u001b[38;5;241m.\u001b[39mexists():\n\u001b[0;32m    267\u001b[0m     get_top_repos(\n\u001b[0;32m    268\u001b[0m         keyword\u001b[38;5;241m=\u001b[39mkeyword,\n\u001b[0;32m    269\u001b[0m         sort_by\u001b[38;5;241m=\u001b[39msort_by,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    273\u001b[0m         save_directory\u001b[38;5;241m=\u001b[39msave_directory\n\u001b[0;32m    274\u001b[0m     )\n\u001b[1;32m--> 275\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfull_repo_save_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m infile:\n\u001b[0;32m    276\u001b[0m     repo_info \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(infile)\n\u001b[0;32m    277\u001b[0m     repo_info \u001b[38;5;241m=\u001b[39m DataProcessor(repo_info)\u001b[38;5;241m.\u001b[39mprocess()\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './top_repo_info_machine learning_best_match_1_10.json'"
     ]
    }
   ],
   "source": [
    "contributors = get_top_contributors(keyword, stop_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c9faaa-3e3b-453e-b7c7-bb156d0c52c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "contributors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006cc993-5b3a-49b6-ba0e-8b637b1a71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Remove duplicates\n",
    "\n",
    "contributors = contributors[~contributors.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7cf4e0b-dac8-4780-9cda-e96a4a8f2c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get top users\n",
    "users = get_top_users(keyword, stop_page=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a3fd6e0-a896-447f-ba6d-5389a18d4116",
   "metadata": {},
   "outputs": [],
   "source": [
    "users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25800ba5-90ab-4272-a179-735351613487",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Combine data\n",
    "all_users = pd.concat([contributors, users])\n",
    "\n",
    "# Remove duplicated users\n",
    "all_users = all_users[~all_users.duplicated()]\n",
    "all_users['real_url'] = all_users.login.apply(lambda login: 'https://github.com/' + login)\n",
    "all_users.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15dc9c99-22e7-40b1-9f6b-ebd5dfd3e2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Map\n",
    "geolocator = Nominatim(user_agent='my_app')\n",
    "\n",
    "all_users_with_locations = all_users[~all_users['location'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56a991dc-b16d-48de-8d1f-2a4caba2d31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_locations(location:str):\n",
    "    try:\n",
    "        return geolocator.geocode(location)\n",
    "    except:\n",
    "        pass\n",
    "def get_lat(location):\n",
    "    return location.latitude\n",
    "   \n",
    "def get_lon(location):\n",
    "    return location.longitude"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
